inherit_from: ./train_data.yaml

experiment_path: experiments/audiocaps/cnn14rnn_trm/

seed: 1

model:
    encoder:
        type: captioning.models.crnn_trm_encoder.CrnnEncoder
        args:
            freeze_cnn: True
            freeze_cnn_bn: True
        cnn:
            type: captioning.models.cnn_encoder.Cnn14Encoder
            args:
                sample_rate: 32000
            pretrained: experiments/pretrained_encoder/Cnn14_mAP=0.431.pth
        rnn:
            type: captioning.models.rnn_encoder.RnnEncoder
            args:
                bidirectional: True
                hidden_size: 256
                dropout: 0.5
                num_layers: 3
                spec_dim: -1
                fc_feat_dim: 2048
                attn_feat_dim: 2048
    decoder:
        type: captioning.models.transformer_decoder.TransformerDecoder
        args:
            vocab_size: 4981
            emb_dim: 256
            fc_emb_dim: 512
            attn_emb_dim: 512
            nlayers: 2
            dropout: 0.2
    type: captioning.models.transformer_model.TransformerModel
    args: {}

specaug: False

optimizer:
    type: torch.optim.Adam
    args:
        lr: !!float 5e-4
        weight_decay: !!float 1e-6

lr_scheduler:
    type: captioning.utils.lr_scheduler.ExponentialDecayScheduler
    args:
        # warmup_iters: 3000
        final_lrs: !!float 5e-7


trainer:
    max_grad_norm: 1.0
    epochs: 25
    save_interval: 5
    lr_update_interval: iteration
    monitor_metric:
        name: score
        mode: max
    include_optim_in_ckpt: False
    finetune: True

inference_args:
    sample_method: beam
    beam_size: 3

scheduled_sampling:
    use: True
    mode: linear
    final_ratio: 0.7

loss:
    type: captioning.losses.loss.LabelSmoothingLoss
    args:
        smoothing: 0.1

swa:
    use: True
    start: 21
